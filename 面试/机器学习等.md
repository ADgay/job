### 说明

机器学习覆盖范围很广，历史悠久，没有时间系统学习了，要有针对性地了解某些方法．比如面试常考SVM\随机森林，就多看一些；比如有的公司做推荐系统/有的做风控/有的做搜索，就需要具体了解一下涉及到哪些知识点．

[CITE1_XYZH的文章](https://www.zhihu.com/question/26726794/answer/151282052)

[机器之心](https://zhuanlan.zhihu.com/p/25327755)

[ Do we need hundreds of classifiers to solve real world classification problems.Fernández-Delgado, Manuel, et al. J. Mach. Learn. Res 15.1 (2014)]()



#### 机器学习

没有最好的分类器，只有最合适的分类器．

- 数据维度越高，随机森林就比AdaBoost强越多，但是整体不及SVM.
- 数据量越大，神经网络就越强

##### 几个基本概念

- 生成模型：获得P(X,Y)的联合概率分布，包括朴素贝叶斯，隐马尔可夫模型，求解时公式如下：
  $$
  P(Y|X)=\frac{P(X,Y)}{P(X)}
  $$

- 判别模型：直接获得条件概率分布P(Y|X)．统计学习方法中大部分方法都是判别模型．

- 分类问题：

  - 准确率：被正确分类样本占总样本的比例．acc

  - 查准率：预测正确的正例与所有预测为证的数据之比．precision.

  - 查全率：预测正确的正例与所有正例之比．recall．

  - ＰＲ曲线：以ｐ为纵坐标ｒ为横坐标的曲线，若以个曲线包围了另一个曲线，则效果更好．

  - 有时以ｐｒ曲线中，p=r的点为衡量标准，越大越好．

  - Ｆ１值：为准确率与召回率的调和均值：
    $$
    \frac2{F_1}=\frac1{P}+\frac1{R}
    $$

- 回归问题：最小二乘法求解．

##### 正则化

​	它是另一种方法（通常是回归方法）的拓展，这种方法会基于模型复杂性对其进行惩罚，它喜欢相对简单能够更好的泛化的模型。

- 岭回归（Ridge Regression）（Ｌ２正则等）

##### SVM

<font color = ff0000>很重要，必考</font>

​	SVM 模型将训练事例表示为空间中的点，它们被映射到一幅图中，由一条明确的、尽可能宽的间隔分开以区分两个类别。随后，新的示例会被映射到同一空间中，并基于它们落在间隔的哪一侧来预测它属于的类别．

​	在非线性可分问题上表现优秀，非常难以训练？？

- 由感知机发展而来：
  - 感知机是一种线性二分类问题，目的是使得误分类数据样本离超平面的总距离最短．
  - 使用梯度下降法求解．
  - 由于结果不唯一，需要加约束得到唯一结果，在此基础上发展出了支持向量机SVM

- 具体推导见统计机器学习
- 使用核技巧，能够处理各种数据，抗干扰性能好，在文本分类上效果好（文本维度高？）

##### 基于实例的算法

​	基于实例的算法（有时也称为基于记忆的学习）是这样学 习算法，不是明确归纳，而是将新的问题例子与训练过程中见过的例子进行对比，这些见过的例子就在存储器中。之所以叫基于实例的算法是因为它直接从训练实例中建构出假设。这意味这，假设的复杂度能随着数据的增长而变化.

​	算法简单、结果易于解读; 计算成本高,不可能用于高维特征空间．

- KNN近邻，一般应用在分类问题．

  - 由距离最近的ｋ个点决定分类类别．
  - 根据不同的ｋ值，空间会被分成不同的块．
  - Lp距离度量．
  - 实现：KD树．如果存下两两之间的距离，这个内积矩阵(GRAM matrix)太大．需要使用特殊结构存储．
    - 按中位数把数据分成一棵平衡二叉树．
    - 最近邻搜索
      - 深入叶结点，得最短距离ｄ．
      - 返回父结点，比较距离．并检查另一个区域是否与球形空间有重合．
      - 若有重合，则对此结点递归调用最近邻搜索．
      - 若无重合，则继续网商，返回父结点，即回到第二步．
  - kd树平均搜索复杂度为log(N)，kd树适合训练样本远大于空间维度的情况．不然效率会极大降低至线性扫描．

  

#####　贝叶斯方法

​	明确应用了贝叶斯定理来解决如分类和回归等问题的方法。用于属性间关系不大的情况，可用于垃圾邮件回收，快速、易于训练、给出了它们所需的资源能带来良好的表现，如果输入变量是相关的，则会出现问题．

- Naive Bayes，朴素贝叶斯．（具体公式见机器学习）
  - 基于贝叶斯定理与特征条件独立假设．
  - 加入拉普拉斯修正，防止概率为零．
- 高斯朴素贝叶斯：没看到
- 半朴素贝叶斯：假设每一个属性仅与另一个属性相关．（没看懂）
- 贝叶斯信念网络：需要优化网络．（没看懂）
- EM算法：处理数据中有隐变量的情况．

##### 决策树

​	能够生成清晰的基于特征的树状结构，简单有效，是很多算法的基础，例如随机森林，提升树，但是容易被攻击．内容有可读性，分类快速。

- 分成三个步骤：
  - 特征选择：
    - 信息增益：经验熵减去条件经验熵，即：选择A为特征后，熵的下降，也就是不确定度的下降。
    - 信息增益比：信息增益与数据集D对特征A的值的熵之比。
  - 决策树生成
    - 根据信息增益是否超过某一个定值来分类，每次数据集会少一些，特征也少一个，直到分类结束。
  - 剪枝
    - 通过极小化决策树整体的损失函数实现。
    - 分为预剪枝与后剪枝
      - 预剪枝通过训练集生成树，每生成一个节点的时候，判断损失函数。预剪枝速度快，但可能因为剪掉了大树干而造成欠拟合。
      - 后剪枝在决策树生成之后此下而上，逐节点剪枝，计算量大但是一定程度上避免了欠拟合。
- ID3：
  - 简单的生成。
  - 只有生成算法，容易产生过拟合。
- C4.5/C5.0（同一方法，两个版本）
  - 生成部分，相比ID3，使用信息增益比替代信息熵。
  - 加入了剪枝策略。
- CART分类回归树
  - 回归树，最小二乘回归树．
  - 分类树，使用基尼指数．
  - 剪枝方法，用的是Breiman的递归方法剪枝，具体怎么实现还不太清楚．
- 连续值处理：
  - 选取中间值划分
- 缺失值处理
  - 若是训练过程中，某数据某属性缺失，基本上是不考虑这些数据，计算熵增益．
  - 若是测试过程中，测试样例某属性缺失，C4.5中会把改数据的权重减小，再放入下一阶段的样本中．
- 多变量决策树（斜决策树）
  - 如果按照单属性分割数据的话，空间之间的间隔都是平行于属性坐标轴的，而多变量决策树则可以斜着分类，减少了树的深度．

##### 回归模型

​	回归是用于估计两种变量之间关系的统计过程。当用于分析因变量和一个 多个自变量之间的关系时，该算法能提供很多建模和分析多个变量的技巧。具体一点说，回归分析可以帮助我们理解当任意一个自变量变化，另一个自变量不变时，因变量变化的典型值。最常见的是，回归分析能在给定自变量的条件下估计出因变量的条件期望。

​	直接快速，但是有严格的假设，需要处理异常值．

- 最小二乘回归
- 线性回归

- 对率回归（LR）
  - 简单的线性模型，输出有概率意义．

##### 神经网络

​	需要大量数据进行训练；训练要求很高的硬件配置；模型处于「黑箱状态」，难以理解内部机制；元参数（Metaparameter）与网络拓扑选择困难。

- 感知机
- 深度学习

##### 集成方法（ensemble）

<font color = ff0000>很重要，必考</font>

​	集成方法是由多个较弱的模型集成模型组，其中的模型可以单独进行训练，并且它们的预测能以某种方式结合起来去做出一个总体预测。当先最先进的预测几乎都使用了算法集成。它比使用单个模型预测出来的结果要精确的多.

- 提升算法（boosting）
  - Adaboost思想，典型如提升树
  - 梯度提升回归树（Gradient Boosted Regression Trees，GBRT）
  - Xgboost是GB算法的高效实现
- bagging

- 随机森林
  - 基于决策树，简单有效，是一种集成学习方法．

##### 降维算法

​	和集簇方法类似，降维追求并利用数据的内在结构，目的在于使用较少的信息总结或描述数据。可处理大规模数据集，难以搞定非线性数据．

- 主成分分析（PCA）．
- 判别分析．

##### 聚类算法

​	聚类算法是指对一组目标进行分类，属于同一组（亦即一个类，cluster）的目标被划分在一组中，与其他组目标相比，同一组目标更加彼此相似（在某种意义上）。让数据变得有意义，结果难以解读，针对不寻常的数据组，结果可能无用。

- K-means
- EM算法

##### 最大熵模型

​	最大熵模型本身不是分类器，它一般是用来判断模型预测结果的好坏的。LR其实就是使用最大熵模型作为优化目标的一个算法．

##### 隐马尔可夫

​	这是一个基于序列的预测方法，核心思想就是通过上一个（或几个）状态预测下一个状态。之所以叫“隐”马尔科夫是因为它的设定是状态本身我们是看不到的，我们只能根据状态生成的结果序列来学习可能的状态。

##### 概率图模型

​	图模型或概率图模型（PGM/probabilistic graphical model）是一种概率模型，一个图（graph）可以通过其表示随机变量之间的条件依赖结构（conditional dependence structure）。模型清晰易理解，确定其依赖的拓扑很困难，有时候也很模糊．

- 贝叶斯网络
- 马尔可夫随机场
- 链图





#### 风控

#### 推荐系统

#### 搜索

